{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 05\n",
    "\n",
    "Name:  Matias Ou    \n",
    "UID: U34955662\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Cost Functions\n",
    "- Kmeans\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "Solving Data Science problems often starts by defining a metric with which to evaluate solutions were you able to find some. This metric is called a cost function. Data Science then backtracks and tries to find a process / algorithm to find solutions that can optimize for that cost function.\n",
    "\n",
    "For example suppose you are asked to cluster three points A, B, C into two non-empty clusters. If someone gave you the solution `{A, B}, {C}`, how would you evaluate that this is a good solution?\n",
    "\n",
    "Notice that because the clusters need to be non-empty and all points must be assigned to a cluster, it must be that two of the three points will be together in one cluster and the third will be alone in the other cluster.\n",
    "\n",
    "In the above solution, if A and B are closer than A and C, and B and C, then this is a good solution. The smaller the distance between the two points in the same cluster (here A and B), the better the solution. So we can define our cost function to be that distance (between A and B here)!\n",
    "\n",
    "The algorithm / process would involve clustering together the two closest points and put the third in its own cluster. This process optimizes for that cost function because no other pair of points could have a lower distance (although it could equal it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means\n",
    "\n",
    "a) (1-dimensional clustering) Walk through Lloyd's algorithm step by step on the following dataset:\n",
    "\n",
    "`[0, .5, 1.5, 2, 6, 6.5, 7]` (note: each of these are 1-dimensional data points)\n",
    "\n",
    "Given the initial centroids:\n",
    "\n",
    "`[0, 2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First assign each point its closest centroid \n",
    "- 2 recompute the center of each cluster: `[0.25, 4.6]`\n",
    "- Assign each point in the data set its closest center `[0, 0.5, 1.5, 2], [6, 6.5, 7]`\n",
    "- recompute the center of each cluster again: `[1.0, 6.5]`\n",
    "- Assign each point in the data set their closest center: `[0, 0.5, 1.5, 2], [6, 6.5, 7]`\n",
    "- And finally convergence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe in plain english what the cost function for k means is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It measures how spread out the data points are within their respective clusters. A lower cost means that the data points are reletively closely clustered around their centroids, giving a better clustering solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) For the same number of clusters K, why could there be very different solutions to the K means algorithm on a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There could be very different solutions for the same given dataset because every time we run the algorithm we are randomly selecting the centroids, so every initialization will lead to a different solution for the same number of k clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Does Lloyd's Algorithm always converge? Why / why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yes it always converges because during every iteration on the centroids of the data oints we recalculate them based on the current assignments of the data points to the centroids. This means that the distance between data points with their centriods is decreasing every iteration. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Follow along in class the implementation of Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.1-cp39-cp39-macosx_10_9_x86_64.whl (10.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.2 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Collecting scipy>=1.5.0\n",
      "  Downloading scipy-1.11.3-cp39-cp39-macosx_10_9_x86_64.whl (37.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 37.3 MB 997 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting joblib>=1.1.1\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/matias/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.25.1)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.1 scipy-1.11.3 threadpoolctl-3.2.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "centers = [[0, 0], [2, 2], [-3, 2], [2, -4]]\n",
    "X, _ = datasets.make_blobs(n_samples=300, centers=centers, cluster_std=1, random_state=0)\n",
    "\n",
    "class KMeans():\n",
    "\n",
    "    def __init__(self, data, k):\n",
    "        self.data = data\n",
    "        self.k = k\n",
    "        self.assignment = [-1 for _ in range(len(data))]\n",
    "        self.snaps = []\n",
    "    \n",
    "    def snap(self, centers):\n",
    "        TEMPFILE = \"temp.png\"\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=self.assignment)\n",
    "        ax.scatter(centers[:,0], centers[:, 1], c='r')\n",
    "        fig.savefig(TEMPFILE)\n",
    "        plt.close()\n",
    "        self.snaps.append(im.fromarray(np.asarray(im.open(TEMPFILE))))\n",
    "\n",
    "\n",
    "    def lloyds(self):\n",
    "        centers = self.data[np.random.choice(len(self.data), self.k, replace=False)]\n",
    "        self.snap(centers)\n",
    "        while True:\n",
    "            new_assignment = [-1 for _ in range(len(self.data))]\n",
    "            for i, x in enumerate(self.data):\n",
    "                new_assignment[i] = np.argmin([np.linalg.norm(x - c) for c in centers])\n",
    "            if new_assignment == self.assignment:\n",
    "                break\n",
    "            self.assignment = new_assignment\n",
    "            for i in range(self.k):\n",
    "                centers[i] = np.mean(self.data[np.array(self.assignment) == i], axis=0)\n",
    "            self.snap(centers)\n",
    "            \n",
    "\n",
    "kmeans = KMeans(X, 6)\n",
    "kmeans.lloyds()\n",
    "images = kmeans.snaps\n",
    "\n",
    "images[0].save(\n",
    "    'kmeans.gif',\n",
    "    optimize=False,\n",
    "    save_all=True,\n",
    "    append_images=images[1:],\n",
    "    loop=0,\n",
    "    duration=500\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Class implementation\n",
    "# import numpy as np\n",
    "# from PIL import Image as im\n",
    "# import matplotlib.pyplot as plt\n",
    "# import sklearn.datasets as datasets\n",
    "\n",
    "# centers = [[0, 0], [2, 2], [-3, 2], [2, -4]]\n",
    "# X, _ = datasets.make_blobs(n_samples=300, centers=centers, cluster_std=1, random_state=0)\n",
    "\n",
    "# class KMeans():\n",
    "\n",
    "#     def __init__(self, data, k):\n",
    "#         self.data = data\n",
    "#         self.k = k\n",
    "#         self.assignment = [-1 for _ in range(len(data))]\n",
    "#         self.snaps = []\n",
    "    \n",
    "#     def distance(self, x, y):\n",
    "#         return np.linalg.norm(x - y)\n",
    "    \n",
    "#     def snap(self, centers):\n",
    "#         TEMPFILE = \"temp.png\"\n",
    "\n",
    "#         fig, ax = plt.subplots()\n",
    "#         ax.scatter(X[:, 0], X[:, 1], c=self.assignment)\n",
    "#         ax.scatter(centers[:,0], centers[:, 1], c='r')\n",
    "#         fig.savefig(TEMPFILE)\n",
    "#         plt.close()\n",
    "#         self.snaps.append(im.fromarray(np.asarray(im.open(TEMPFILE))))\n",
    "\n",
    "#     def initialize(self):\n",
    "#         return self.data[np.random.choice(len(self.data), self.k, replace=False)]\n",
    "\n",
    "#     def assign(self, centers):\n",
    "#         for i in range(len(self.data)):\n",
    "#             min = self.distance(self.data[i], centers[0])\n",
    "#             self.assignment[i] = 0\n",
    "#             # self.assignment = 0\n",
    "#             for j in range(len(centers)):\n",
    "#                 dist = self.distance(self.data[i], centers[j])\n",
    "#                 if dist < min:\n",
    "#                     min = dist\n",
    "#                     self.assignment[i] = j\n",
    "\n",
    "#         # for i, x in enumerate(self.data):\n",
    "#         #     self.assignment[i] = np.argmin([np.linalg.norm(x - c) for c in centers])\n",
    "\n",
    "#     def is_diff_clusters(self, centers, new_centers):\n",
    "#         for i in range(len(centers)):\n",
    "#             if self.distance(centers[i], new_centers[i]) != 0:\n",
    "#                 return True\n",
    "#         return False\n",
    "\n",
    "#     def get_centers(self):\n",
    "#         new_centers = []\n",
    "#         for i in set(self.assignment): # for every different assignment\n",
    "#             cluster = self.data[np.array(self.assignment) == i]\n",
    "#             new_centers.append(np.mean(cluster, axis=0))\n",
    "\n",
    "#         return np.array(new_centers)\n",
    "    \n",
    "#     def lloyds(self):\n",
    "#         centers = self.initialize()\n",
    "#         self.assign(centers)\n",
    "#         self.snap(centers)\n",
    "#         new_centers = self.get_centers()\n",
    "\n",
    "#         while self.is_diff_clusters(centers, new_centers):\n",
    "#             self.assign(new_centers)\n",
    "#             centers = new_centers\n",
    "#             self.snap(new_centers)\n",
    "#             new_centers = self.get_centers()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
